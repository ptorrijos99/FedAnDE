/*
 *  The MIT License (MIT)
 *  
 *  Copyright (c) 2022 Universidad de Castilla-La Mancha, España
 *  
 *  Permission is hereby granted, free of charge, to any person obtaining a copy
 *  of this software and associated documentation files (the "Software"), to deal
 *  in the Software without restriction, including without limitation the rights
 *  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 *  copies of the Software, and to permit persons to whom the Software is
 *  furnished to do so, subject to the following conditions:
 *  
 *  The above copyright notice and this permission notice shall be included in all
 *  copies or substantial portions of the Software.
 *  
 *  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 *  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 *  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 *  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 *  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 *  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 *  SOFTWARE.
 */
/**
 *    ExperimentUtils.java
 *    Copyright (C) 2023 Universidad de Castilla-La Mancha, España
 *
 * @author Pablo Torrijos Arenas
 *
 */

package fedAnDE.experiments.utils;

import fedAnDE.data.Data;
import weka.classifiers.AbstractClassifier;
import weka.classifiers.evaluation.Evaluation;
import weka.core.*;

import java.io.*;
import java.util.*;
import java.util.logging.Level;
import java.util.logging.Logger;

public class ExperimentUtils {

    public static int experimentID = -1;

    private static final Object fileLock = new Object();

    public static void saveExperiment(String path, String header, String data) {
        // Create the directory if it does not exist
        File directory = new File(path.substring(0, path.lastIndexOf("/")));
        if (!directory.exists()) {
            directory.mkdirs();
        }

        File file = new File(path);
        synchronized (fileLock) {
            try (BufferedWriter csvWriter = new BufferedWriter(new FileWriter(file, true))) {
                if (file.length() == 0) {
                    csvWriter.append(header);
                }
                csvWriter.append(data);
            } catch (IOException ex) {
                Logger.getLogger(ExperimentUtils.class.getName()).log(Level.SEVERE, null, ex);
            }
        }
    }

    public static String[] readParametersFromArgs(String[] args) {
        int i = 0;
        for (String string : args) {
            System.out.println("arg[" + i + "]: " + string);
            i++;
        }
        int index = Integer.parseInt(args[0]);
        String paramsFileName = args[1];

        ExperimentUtils.experimentID = index;

        // Read the parameters from args
        String[] parameters = null;
        try (BufferedReader br = new BufferedReader(new FileReader(paramsFileName))) {
            String line;
            for (i = 0; i < index; i++)
                br.readLine();
            line = br.readLine();
            parameters = line.split(" ");
        } catch (Exception e) {
            System.out.println(e);
        }

        System.out.println("Number of hyperparams: " + parameters.length);
        i = 0;
        for (String string : parameters) {
            System.out.println("Param[" + i + "]: " + string);
            i++;
        }

        return parameters;
    }

    /**
     * Get the metrics of the model. The metrics are accuracy, precision, recall,
     * F1-score, and prediction time.
     *
     * @param instances The instances.
     * @return The metrics of the model in the form of a string.
     */
    public static String getClassificationMetrics(AbstractClassifier classifier, Instances instances) {
        Evaluation evaluation;
        try {
            evaluation = new Evaluation(instances);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

        // Initialize the start time of the evaluation
        double startTime = System.currentTimeMillis();

        try {
            evaluation.evaluateModel(classifier, instances);
        } catch (Exception e) {
            e.printStackTrace();
        }

        // Get the time of the evaluation and convert it to seconds
        double time = (System.currentTimeMillis() - startTime) / 1000.0;

        int numClasses = instances.numClasses();
        double accuracy = evaluation.pctCorrect() / 100.0;
        double f1 = 0.0;
        double precision = 0.0;
        double recall = 0.0;
        double metric;

        for (int i = 0; i < numClasses; i++) {
            // If the classifier predicts no instances of a class
            // or they not exist, the metrics must be set to zero
            metric = evaluation.precision(i);
            precision += Double.isNaN(metric) ? 0 : metric;
            metric = evaluation.recall(i);
            recall += Double.isNaN(metric) ? 0 : metric;
            metric = evaluation.fMeasure(i);
            f1 += Double.isNaN(metric) ? 0 : metric;
        }

        // Compute the macro average of the metrics
        precision /= numClasses;
        recall /= numClasses;
        f1 /= numClasses;

        return accuracy + "," + precision + "," + recall + "," + f1 + "," + time + ",";
    }

    /**
     * Get the metrics of a ensemble model. The metrics are accuracy, precision,
     * recall, F1-score, and prediction time.
     *
     * @param ensemble           The ensemble of classifiers.
     * @param syntheticClassMaps The synthetic class maps.
     * @param instances          The instances.
     * @return The metrics of the model in the form of a string.
     */
    public static String getClassificationMetricsEnsemble(List<AbstractClassifier> ensemble,
            List<Map<String, Integer>> syntheticClassMaps, Instances instances) {
        Evaluation evaluation;
        try {
            evaluation = new Evaluation(instances);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

        double startTime = System.currentTimeMillis();

        // New variables for probabilistic metrics
        double sumLogLoss = 0.0;
        double sumBrier = 0.0;
        int N = instances.numInstances();
        int numClasses = instances.numClasses();

        try {
            EnsembleClassifier ensembleClassifier = new EnsembleClassifier(ensemble, syntheticClassMaps);
            ensembleClassifier.buildClassifier(instances);

            // Standard Weka evaluation
            evaluation.evaluateModel(ensembleClassifier, instances);

            // Manual calculation for LogLoss and Brier to match Python
            for (int i = 0; i < N; i++) {
                Instance inst = instances.instance(i);
                double[] probs = ensembleClassifier.distributionForInstance(inst);
                int trueClass = (int) inst.classValue();

                // LogLoss with epsilon clipping
                double epsilon = 1e-15;
                double p = Math.max(Math.min(probs[trueClass], 1 - epsilon), epsilon);
                sumLogLoss -= Math.log(p);

                // Multiclass Brier Score (Sum of Squared Errors)
                double instanceBrier = 0.0;
                for (int k = 0; k < numClasses; k++) {
                    double target = (k == trueClass) ? 1.0 : 0.0;
                    instanceBrier += Math.pow(probs[k] - target, 2);
                }
                sumBrier += instanceBrier;
            }

        } catch (Exception e) {
            e.printStackTrace();
        }

        double time = (System.currentTimeMillis() - startTime) / 1000.0;

        double accuracy = evaluation.pctCorrect() / 100.0;
        double precision = 0.0;
        double recall = 0.0;
        double f1 = 0.0;
        double metric;

        for (int i = 0; i < numClasses; i++) {
            metric = evaluation.precision(i);
            precision += Double.isNaN(metric) ? 0 : metric;
            metric = evaluation.recall(i);
            recall += Double.isNaN(metric) ? 0 : metric;
            metric = evaluation.fMeasure(i);
            f1 += Double.isNaN(metric) ? 0 : metric;
        }

        precision /= numClasses;
        recall /= numClasses;
        f1 /= numClasses;

        double finalLogLoss = sumLogLoss / N;
        double finalBrier = sumBrier / N;

        // Return matched format: Acc, Pr, Rc, F1, LogLoss, Brier, Time
        return accuracy + "," + precision + "," + recall + "," + f1 + "," + finalLogLoss + "," + finalBrier + "," + time
                + ",";
    }

    /**
     * Computes the L1/L2 sensitivity K = (d - n) * C(d - 1, n) based on dataset and
     * algorithm options.
     *
     * @param data             the client data (must be Weka_Instances)
     * @param algorithmOptions the algorithm options containing the -S flag for
     *                         structure
     * @return the computed sensitivity value (number of affected cells)
     */
    public static int computeSensitivity(Data data, String[] algorithmOptions) {
        int d = ((Instances) data.getData()).numAttributes() - 1;

        algorithmOptions = Arrays.copyOf(algorithmOptions, algorithmOptions.length);
        String structure;
        try {
            structure = weka.core.Utils.getOption("S", algorithmOptions);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

        int n = 0;
        if (structure.startsWith("A") && structure.endsWith("DE")) {
            n = Integer.parseInt(structure.substring(1, structure.length() - 2));
        }

        return (d - n) * binomial(d - 1, n);
    }

    public static int binomial(int n, int k) {
        if (k < 0 || k > n)
            return 0;
        if (k == 0 || k == n)
            return 1;
        int res = 1;
        for (int i = 1; i <= k; i++) {
            res = res * (n - (k - i)) / i;
        }
        return res;
    }
}

class EnsembleClassifier extends AbstractClassifier {

    private final List<AbstractClassifier> ensemble;
    private final List<Map<String, Integer>> syntheticClassMaps;
    private Instances header;
    private int numClasses;

    public EnsembleClassifier(List<AbstractClassifier> ensemble, List<Map<String, Integer>> syntheticClassMaps) {
        this.ensemble = ensemble;
        this.syntheticClassMaps = syntheticClassMaps;
    }

    @Override
    public void buildClassifier(Instances data) {
        this.header = data;
        this.numClasses = data.classAttribute().numValues();
    }

    @Override
    public double[] distributionForInstance(Instance instance) throws Exception {
        double[] yVotes = new double[numClasses];
        ArrayList<Object> classValues = Collections.list(header.classAttribute().enumerateValues());

        for (int j = 0; j < ensemble.size(); j++) {
            AbstractClassifier clf = ensemble.get(j);
            Map<String, Integer> classMap = syntheticClassMaps.get(j);
            ArrayList<String> synthValues = new ArrayList<>(classMap.keySet());

            Instances syntheticHeader = new Instances(header, 0);
            syntheticHeader.setClassIndex(-1);
            syntheticHeader.deleteAttributeAt(header.classIndex());
            syntheticHeader.insertAttributeAt(new Attribute("synthetic_class", synthValues),
                    syntheticHeader.numAttributes());
            syntheticHeader.setClassIndex(syntheticHeader.numAttributes() - 1);

            Instance synthetic = new weka.core.DenseInstance(syntheticHeader.numAttributes());
            synthetic.setDataset(syntheticHeader);

            int aIdx = 0;
            for (int a = 0; a < instance.numAttributes(); a++) {
                if (a == header.classIndex())
                    continue;
                synthetic.setValue(aIdx++, instance.value(a));
            }

            double[] dist = clf.distributionForInstance(synthetic);
            double[] syntheticVotes = new double[numClasses];
            double sum = 0;

            for (int s = 0; s < dist.length; s++) {
                String synthLabel = synthValues.get(s);
                String origLabel = synthLabel.contains("|||")
                        ? synthLabel.substring(synthLabel.lastIndexOf("|||") + 3)
                        : synthLabel;
                int y = classValues.indexOf(origLabel);
                syntheticVotes[y] += dist[s];
                sum += dist[s];
            }

            if (sum > 0) {
                for (int y = 0; y < numClasses; y++) {
                    yVotes[y] += syntheticVotes[y] / sum;
                }
            }
        }

        // Normalize votes
        double total = Arrays.stream(yVotes).sum();
        if (total > 0) {
            for (int i = 0; i < yVotes.length; i++) {
                yVotes[i] /= total;
            }
        }

        return yVotes;
    }
}
